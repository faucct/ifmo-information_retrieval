# Машинное обучение ранжированию (LETOR)

## Обучение модели ранжирования на данных [“Интернет-математика 2009”](https://academy.yandex.ru/events/data_analysis/grant2009/)

Данные представляли собой пары запрос-документ с идентификатором запроса, 245 неизвестными численными признаками и значением релевантности этой пары.

Модель обучалась с помощью библиотеки [CatBoost](https://catboost.ai).

Сперва данные были разбиты на три части:
* 45% train, использованные для обучения
* 5% validate, для преждевременной остановки при обучении модели
* 50% holdout, по которым выбиралась лучшая модель

Попробовал семь метрик:
* три поточечные: MAE, Poisson и RMSE
* две pairwise: PairLogit и PairLogitPairwise
* две groupwise: YetiRank и YetiRankPairwise

Значения NDCG@20 обученных моделей, посчитанные на holdout сете:

| Метрика, по которой обучалась модель | Среднее | Медиана |
|--------------------------------------|---------|---------|
| MAE                                  | 0.773   | 0.771   |
| RMSE                                 | 0.776   | 0.775   |
| Poisson                              | 0.777   | 0.776   |
| PairLogit                            | 0.776   | 0.773   |
| PairLogitPairwise                    | 0.78    | 0.77    |
| YetiRank                             | 0.774   | 0.772   |
| YetiRankPairwise                     | 0.777   | 0.774   |

![NDCG@20](practice_1/imat2009_ndcg@20.png)

По результатам на holdout сете была выбрана модель, оптимизирующая метрику PairLogitPairwise.

## Обучение модели ранжирования на данных By.Web

В качестве признаков были использованы следующие:
* Длина запроса в буквах
* Длина запроса в словах
* Длина документа в буквах
* Длина документа в словах
* Встречается ли строка запроса в документе
* Доля слов из запроса, встреченных в тексте
* Минимальный размер окна в документе в котором есть все слова запроса. Если такого окна нет, то длинна документа плюс 1.
Величина нормировалась на число уникальных слов запроса, после чего из полученного вычиталась 1. 
* pagerank
* BM25

Перед расчетом признаков документ и запрос приводились к нижнему регистру.

 Разбиение датасета:
* 90% train
* 10% validate
* holdout. Датасет 2009 года

Значения NDCG@20 обученных моделей, посчитанные на holdout сете:

| Метрика, по которой обучалась модель | Среднее | Медиана |
|--------------------------------------|---------|---------|
| MAE	 | 0.300 | 0.310 | 
| RMSE	 | 0.368 | 0.369 | 
| Poisson	 | 0.365 | 0.365 | 
| PairLogit	 | 0.380 | 0.380 | 
| PairLogitPairwise	 | 0.320 | 0.318 | 
| YetiRank	 | 0.381 | 0.397 | 

 Для важности признаков использовалась встроенная в catboost функция `get_feature_importance`

| Признак | Значимость для MAE | Значимость для YetiRankPairwise |
|--------------------------------------|---------|---|
| Длина запроса в буквах | 4.035 | -0.004 |
| Длина документа в буквах | 9.705  | -0.005 |
| Длина запроса в словах | 3.184 | 0 |
| Длина документа в словах | 4.915 | -0.001 |
| Встречается ли строка запроса в документе | 13.639 | 0.003 |
| Доля слов из запроса, встреченных в тексте | 14.335 | 0.0118 |
| Минимальный размер окна в документе, в котором есть все слова запроса. Если такого окна нет, то длина документа плюс 1. | 32.477 | 0.001 | 
| pagerank | 0.731 | -0.001 |
| BM25 | 16.978 | 0.0648 |
